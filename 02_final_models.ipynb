{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e23fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For operating system dependent functionality\n",
    "import time  # For timing code execution\n",
    "import re  # For regular expressions\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import nltk  # For natural language processing tasks\n",
    "from nltk.corpus import stopwords  # For stopwords\n",
    "from nltk.stem import WordNetLemmatizer  # For word lemmatization\n",
    "\n",
    "# For Gensim models and functionalities\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import LdaModel, TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import spacy  # For advanced natural language processing\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff84bef",
   "metadata": {},
   "source": [
    "## Model 1 - Guided LDA (Manual Approach) utilizing Bigrams and TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2514f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time taken in mins is 0\n"
     ]
    }
   ],
   "source": [
    "# Define your directory and file name\n",
    "directory = \"D:/2_nlp\"\n",
    "file_name = \"documents_with_bigrams.xlsx\"\n",
    "full_path = os.path.join(directory, file_name)\n",
    "\n",
    "start_time = time.time()\n",
    "# Load the Excel file\n",
    "df_loaded = pd.read_excel(full_path)\n",
    "end_time = time.time()\n",
    "# Now, documents_with_bigrams_loaded contains your original list of lists structure\n",
    "print(\"The total time taken in mins is {}\".format(round((end_time - start_time) / 60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880ea6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda_model(documents, num_topics, no_below, no_above, total_passes, random_state, low_value):\n",
    "    \"\"\"\n",
    "    Trains an LDA model using documents that have been preprocessed, including phrase detection and NER.\n",
    "    \n",
    "    Parameters:\n",
    "    - documents: List of preprocessed documents, each represented as a list of tokens.\n",
    "    - num_topics: The desired number of topics.\n",
    "    - no_below: Filter out tokens that appear in fewer than 'no_below' documents.\n",
    "    - no_above: Filter out tokens that appear in more than 'no_above' proportion of documents.\n",
    "    - total_passes: Number of passes through the corpus during training.\n",
    "    - random_state: Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - lda_model: The trained LDA model.\n",
    "    - dictionary: Gensim dictionary created from the documents.\n",
    "    - corpus: Document-term matrix used for LDA training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dictionary and filter extremes\n",
    "    dictionary = Dictionary(documents)\n",
    "    dictionary.filter_extremes(no_below=no_below, no_above=no_above)\n",
    "    \n",
    "    # Create the Document-Term Matrix\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "    \n",
    "    # Apply TF-IDF filtering\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    tfidf_corpus = [[(id, freq) for id, freq in doc if tfidf.idfs[id] > low_value] for doc in corpus]\n",
    "    \n",
    "    # Initialize and train the LDA model\n",
    "    lda_model = LdaModel(corpus=tfidf_corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                         passes=total_passes, random_state=random_state)\n",
    "    \n",
    "    return lda_model, dictionary, tfidf_corpus\n",
    "\n",
    "def emphasize_seed_words(document, seed_words, factor):\n",
    "    \"\"\"\n",
    "    Duplicate seed words in the document to make them more influential by a specified factor.\n",
    "    \"\"\"\n",
    "    emphasized_document = []\n",
    "    for word in document:\n",
    "        emphasized_document.append(word)\n",
    "        if word in seed_words:\n",
    "            emphasized_document.extend([word] * (factor - 1))  # Duplicate seed words by the factor\n",
    "    return emphasized_document\n",
    "\n",
    "# Update your document preparation to include seed word emphasis\n",
    "def prepare_documents(df, seed_topics, factor):\n",
    "    # Ensure all entries are strings and handle missing values\n",
    "    documents = df['documents'].fillna('').astype(str).str.split().tolist()\n",
    "    seed_words = [word for topic_words in seed_topics.values() for word in topic_words]\n",
    "    emphasized_documents = [emphasize_seed_words(doc, seed_words, factor) for doc in documents]\n",
    "    return emphasized_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6587731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor: 10, no_below: 15, no_above: 0.2, low_value: 0.1, Coherence: 0.4713707960728266, Time: 26 minutes\n",
      "Topics for the current model:\n",
      "Topic: 0 \n",
      "Words: 0.089*\"state\" + 0.049*\"president\" + 0.028*\"government\" + 0.019*\"law\" + 0.018*\"member\" + 0.014*\"congress\" + 0.011*\"election\" + 0.009*\"senate\" + 0.008*\"political\" + 0.007*\"policy\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.106*\"house\" + 0.090*\"room\" + 0.041*\"home\" + 0.019*\"property\" + 0.015*\"rent\" + 0.014*\"estate\" + 0.013*\"apartment\" + 0.006*\"new\" + 0.004*\"car\" + 0.004*\"lot\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.075*\"time\" + 0.041*\"man\" + 0.021*\"life\" + 0.019*\"world\" + 0.010*\"thought\" + 0.008*\"one\" + 0.007*\"idea\" + 0.006*\"mind\" + 0.005*\"reason\" + 0.005*\"said\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.089*\"club\" + 0.081*\"game\" + 0.055*\"team\" + 0.052*\"play\" + 0.045*\"building\" + 0.037*\"win\" + 0.035*\"season\" + 0.023*\"event\" + 0.021*\"score\" + 0.019*\"player\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.098*\"home\" + 0.055*\"school\" + 0.044*\"church\" + 0.043*\"member\" + 0.038*\"meeting\" + 0.005*\"john\" + 0.004*\"ceremony\" + 0.004*\"william\" + 0.004*\"son\" + 0.004*\"street\"\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "seed_topics = {\n",
    "    \"Sports\": [\"game\", \"team\", \"season\", \"play\", \"club\", \"win\", \"match\", \"score\", \"player\", \"coach\"],\n",
    "    \"Rentals & Real Estate\": [\"house\", \"home\", \"room\", \"property\", \"rent\", \"estate\", \"apartment\", \"building\", \"lease\", \"mortgage\"],\n",
    "    \"Philosophy & Thought\": [\"time\", \"life\", \"man\", \"world\", \"philosophy\", \"thought\", \"mind\", \"idea\", \"reason\", \"belief\"],\n",
    "    \"Community Gatherings/Events\": [\"church\", \"school\", \"event\", \"member\", \"community\", \"meeting\", \"ceremony\", \"celebration\", \"gathering\", \"festival\"],\n",
    "    \"Politics/Government\": [\"president\", \"state\", \"government\", \"senate\", \"congress\", \"election\", \"policy\", \"law\", \"political\", \"diplomacy\"]\n",
    "}\n",
    "factor = 10\n",
    "\n",
    "seeded_documents = prepare_documents(df_loaded, seed_topics, factor)\n",
    "# Set fixed hyperparameters\n",
    "num_topics = 5\n",
    "total_passes = 3\n",
    "\n",
    "# Define the range of hyperparameters to explore\n",
    "no_below = 15  # Example: Minimum document frequency\n",
    "no_above = 0.2  # Example: Maximum document frequency proportion\n",
    "low_value = 0.1  # TF-IDF low value cut-off\n",
    "\n",
    "start_time_iter = time.time()  # Start time for this iteration\n",
    "\n",
    "# Train the LDA model with the current set of hyperparameters\n",
    "\n",
    "lda_model, dictionary, tfidf_corpus = train_lda_model(seeded_documents, num_topics=num_topics, no_below=no_below, no_above=no_above, total_passes=total_passes, random_state=100, low_value=low_value)\n",
    "\n",
    "# Calculate Coherence Score using c_v measure\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=seeded_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_cv = coherence_model_lda.get_coherence()\n",
    "\n",
    "end_time_iter = time.time()  # End time for this iteration\n",
    "iter_duration = round((end_time_iter - start_time_iter) / 60)\n",
    "\n",
    "print(f\"factor: {factor}, no_below: {no_below}, no_above: {no_above}, low_value: {low_value}, Coherence: {coherence_lda_cv}, Time: {iter_duration} minutes\")\n",
    "\n",
    "# Print topics for the current model\n",
    "print(\"Topics for the current model:\")\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729133f4",
   "metadata": {},
   "source": [
    "### Topic 0 : Political Governance\n",
    "### Topic 1: Rentals/Real estate/living spaces\n",
    "### Topic 2: Philosophical concepts\n",
    "### Topic 3: Sports\n",
    "### Topic 4: Community gatherings/Social life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded2424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af3e99af",
   "metadata": {},
   "source": [
    "## Model 2 - Unguided LDA utilizing Bigrams and TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799c247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_with_bigrams = [str(doc).split(' ') for doc in df_loaded['documents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1267126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_below: 15, no_above: 0.2, low_value: 0.01, Coherence: 0.5292118758821858, Time: 28 minutes\n",
      "Topics for the current model:\n",
      "Topic: 0 \n",
      "Words: 0.010*\"game\" + 0.007*\"two\" + 0.007*\"one\" + 0.007*\"team\" + 0.006*\"first\" + 0.006*\"play\" + 0.005*\"new_york\" + 0.005*\"three\" + 0.004*\"season\" + 0.004*\"club\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.011*\"room\" + 0.008*\"new\" + 0.008*\"car\" + 0.007*\"lot\" + 0.006*\"500\" + 0.006*\"home\" + 0.006*\"phone\" + 0.006*\"350\" + 0.006*\"house\" + 0.005*\"ave\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.009*\"one\" + 0.006*\"said\" + 0.005*\"would\" + 0.005*\"time\" + 0.004*\"man\" + 0.004*\"day\" + 0.004*\"many\" + 0.003*\"say\" + 0.003*\"way\" + 0.003*\"two\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.010*\"home\" + 0.007*\"john\" + 0.005*\"church\" + 0.005*\"son\" + 0.005*\"william\" + 0.005*\"school\" + 0.005*\"street\" + 0.005*\"member\" + 0.005*\"miss\" + 0.004*\"club\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.009*\"state\" + 0.009*\"said\" + 0.006*\"year\" + 0.005*\"new\" + 0.005*\"would\" + 0.005*\"today\" + 0.005*\"president\" + 0.004*\"district\" + 0.004*\"may\" + 0.004*\"committee\"\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Set fixed hyperparameters\n",
    "num_topics = 5\n",
    "total_passes = 3\n",
    "no_below = 15\n",
    "no_above = 0.2\n",
    "low_value = 0.01\n",
    "\n",
    "start_time_iter = time.time()  # Start time for this iteration\n",
    "            \n",
    "# Train the LDA model with the current set of hyperparameters\n",
    "\n",
    "lda_model, dictionary, tfidf_corpus = train_lda_model(documents_with_bigrams, num_topics=num_topics, no_below=no_below, no_above=no_above, total_passes=total_passes, random_state=100, low_value=low_value)\n",
    "\n",
    "# Calculate Coherence Score using c_v measure\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=documents_with_bigrams, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_cv = coherence_model_lda.get_coherence()\n",
    "\n",
    "end_time_iter = time.time()  # End time for this iteration\n",
    "iter_duration = round((end_time_iter - start_time_iter) / 60)\n",
    "\n",
    "print(f\"no_below: {no_below}, no_above: {no_above}, low_value: {low_value}, Coherence: {coherence_lda_cv}, Time: {iter_duration} minutes\")\n",
    "            \n",
    "# Print topics for the current model\n",
    "print(\"Topics for the current model:\")\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059c885",
   "metadata": {},
   "source": [
    "### Topic 0 : Political Governance\n",
    "### Topic 1: Rentals/Real estate/living spaces\n",
    "### Topic 2: Philosophical concepts\n",
    "### Topic 3: Sports\n",
    "### Topic 4: Community gatherings/Social life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdde1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e81db3e",
   "metadata": {},
   "source": [
    "## Model 3 - Guided LDA with CorEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8750d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max features parameter value is 20000\n",
      "Topic 0:\n",
      "game 0.24599339220013333 1.0\n",
      "team 0.15906783920078568 1.0\n",
      "play 0.1543643886541341 1.0\n",
      "season 0.09097637130320244 1.0\n",
      "win 0.08268616178949217 1.0\n",
      "club 0.07707404226812839 1.0\n",
      "player 0.07386469422388808 1.0\n",
      "score 0.06779579290373153 1.0\n",
      "two 0.04583469134462471 1.0\n",
      "coach 0.04485859775810235 1.0\n",
      "\n",
      "Topic 1:\n",
      "room 0.11916416528342097 1.0\n",
      "house 0.06689389157650763 1.0\n",
      "home 0.06389565580179099 1.0\n",
      "ave 0.06253313567951498 1.0\n",
      "rent 0.05792231026811728 1.0\n",
      "call 0.050620644632142615 1.0\n",
      "500 0.04216220984559702 1.0\n",
      "bath 0.04053681365725354 1.0\n",
      "350 0.03634583043422621 1.0\n",
      "phone 0.03116802509117465 1.0\n",
      "\n",
      "Topic 2:\n",
      "time 0.24966413344011112 1.0\n",
      "one 0.10377713339238194 1.0\n",
      "man 0.10287236864570998 1.0\n",
      "life 0.08020033268085972 1.0\n",
      "world 0.07729381716308922 1.0\n",
      "thought 0.06347823702770003 1.0\n",
      "reason 0.053425403759152806 1.0\n",
      "idea 0.050720793705444606 1.0\n",
      "make 0.05010709963558555 1.0\n",
      "many 0.05002916299891667 1.0\n",
      "\n",
      "Topic 3:\n",
      "church 0.21007647134907936 1.0\n",
      "member 0.14097619880433537 1.0\n",
      "school 0.11435536456418363 1.0\n",
      "meeting 0.0875887165802953 1.0\n",
      "john 0.05276156580067868 1.0\n",
      "son 0.04774710639568542 1.0\n",
      "william 0.04325405775412366 1.0\n",
      "daughter 0.03508865545395615 1.0\n",
      "james 0.03400208649933068 1.0\n",
      "george 0.03202763073399315 1.0\n",
      "\n",
      "Topic 4:\n",
      "state 0.17195214495385827 1.0\n",
      "government 0.15145215000482437 1.0\n",
      "president 0.1328633823717801 1.0\n",
      "said 0.09947742088870766 1.0\n",
      "would 0.08614845188919425 1.0\n",
      "congress 0.08054288219688788 1.0\n",
      "law 0.06596582824741888 1.0\n",
      "policy 0.06251123362636049 1.0\n",
      "senate 0.057309293597756245 1.0\n",
      "political 0.04488045138103228 1.0\n",
      "\n",
      "\n",
      "The total time taken in mins is 3\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def perform_guided_topic_modeling(df_loaded, seed_words, num_topics=5, ngram_range=(1,1), max_features=2000, anchor_strength=3, random_state=100):\n",
    "    \"\"\"\n",
    "    Performs guided topic modeling using CorEx on a given dataset with seed words for topics.\n",
    "    \"\"\"\n",
    "    # Convert the documents column to a list of documents\n",
    "    df_loaded['documents'] = df_loaded['documents'].fillna('')\n",
    "    documents_list = df_loaded['documents'].tolist()\n",
    "\n",
    "    # Create a document-term matrix\n",
    "    vectorizer = CountVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "    doc_word_matrix = vectorizer.fit_transform(documents_list)\n",
    "    #doc_word_matrix = doc_word_matrix.toarray()  # Convert to array if needed\n",
    "\n",
    "    words = list(np.asarray(vectorizer.get_feature_names_out()))\n",
    "\n",
    "    # Instantiate and fit the CorEx model\n",
    "    model = ct.Corex(n_hidden=num_topics, seed=random_state)\n",
    "    model.fit(doc_word_matrix, words=words, anchors=seed_words, anchor_strength=anchor_strength)\n",
    "\n",
    "    return model, words\n",
    "\n",
    "# Assuming df_loaded is your loaded DataFrame with the 'documents' column\n",
    "num_topics = 5\n",
    "ngram_range = (1,1)\n",
    "max_features = 20000\n",
    "anchor_strength = 3\n",
    "random_state = 100\n",
    "seed_words = [\n",
    "    [\"game\", \"team\", \"season\", \"play\", \"club\", \"win\", \"match\", \"score\", \"player\", \"coach\"],\n",
    "    [\"house\", \"home\", \"room\", \"property\", \"rent\", \"estate\", \"apartment\", \"building\", \"lease\", \"mortgage\"],\n",
    "    [\"time\", \"life\", \"man\", \"world\", \"philosophy\", \"thought\", \"mind\", \"idea\", \"reason\", \"belief\"],\n",
    "    [\"church\", \"school\", \"event\", \"member\", \"community\", \"meeting\", \"ceremony\", \"celebration\", \"gathering\", \"festival\"],\n",
    "    [\"president\", \"state\", \"government\", \"senate\", \"congress\", \"election\", \"policy\", \"law\", \"political\", \"diplomacy\"]\n",
    "]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model, words = perform_guided_topic_modeling(df_loaded, seed_words, num_topics=num_topics, ngram_range=ngram_range,\n",
    "                                     max_features=max_features, anchor_strength=anchor_strength, random_state=random_state)\n",
    "\n",
    "topics = model.get_topics()\n",
    "print(\"Max features parameter value is {}\".format(max_features))\n",
    "for n, topic in enumerate(topics):\n",
    "    print(f\"Topic {n}:\")\n",
    "    for word, weight, correlation in topic:\n",
    "        print(f\"{word} {weight} {correlation}\")\n",
    "    print()\n",
    "\n",
    "print()\n",
    "end_time = time.time()\n",
    "print(\"The total time taken in mins is {}\".format(round((end_time - start_time) / 60)))\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc28d2",
   "metadata": {},
   "source": [
    "### Topic 0 : Political Governance\n",
    "### Topic 1: Rentals/Real estate/living spaces\n",
    "### Topic 2: Philosophical concepts\n",
    "### Topic 3: Sports\n",
    "### Topic 4: Community gatherings/Social life"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
